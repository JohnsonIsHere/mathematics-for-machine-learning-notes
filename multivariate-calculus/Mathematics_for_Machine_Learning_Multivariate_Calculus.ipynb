{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8dc64a",
   "metadata": {},
   "source": [
    "# A. Introduction to Multivariate Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd10a63",
   "metadata": {},
   "source": [
    "## A1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acffb34",
   "metadata": {},
   "source": [
    "*  What are functions? \n",
    "   *  A function is a mathematical relationship between inputs and an output. It can be thought of as a machine that takes in one or more variables and produces a single, corresponding result. For example, a function for the temperature of a room might take in the coordinates ($x$,$y$,$z$) and time ($t$) as inputs and return the temperature at that specific point and time.\n",
    "   *  The notation $f(x)$ represents \"f as a function of x\", not \"f multiplied by x.\" This can be a point of confusion due to its seemingly arbitrary nature, but it's a standard convention in mathematical language.\n",
    "* The creative essence of science\n",
    "  * Selecting a function to model real-world data is a core, creative step in science and machine learning. This process involves formulating a **hypothesis**—a candidate function that could represent the relationship you're observing. Without this initial creative step, there would be nothing to test or investigate.\n",
    "* Introduction to Calculus\n",
    "  * **Calculus** is the study of how functions change with respect to their input variables. It provides a set of tools to investigate and manipulate these functions. By understanding calculus, you can analyze the behavior of functions and use them to model complex phenomena in the real world.\n",
    "* Gradients and Derivatives\n",
    "  * A great way to visualize this concept is with a **speed-time graph**.\n",
    "  * ![Speed time graph](images/speed_time_graph.png)\n",
    "\n",
    "    * The **gradient** (or slope) of the graph at any point represents the **rate of change** of speed with respect to time, which is the **acceleration**.\n",
    "    * A positive gradient indicates acceleration, a negative gradient indicates deceleration, and a zero gradient (a flat horizontal line) means constant speed with zero acceleration.\n",
    "    * The gradient at a single point is called the **local gradient** and can be visualized as the slope of a tangent line that touches the curve at that point.\n",
    "  * By finding the local gradient at every point on a continuous function, we can create an entirely new function called its **derivative**. The derivative describes the original function's slope at every point.\n",
    "* Higher-Order Derivatives and Anti-Derivatives\n",
    "  * This process can be repeated. The derivative of the acceleration function is called the **jerk**, which represents the rate of change of acceleration. This concept is useful for describing the \"jerky\" motion of a car as it starts and stops. The jerk is the second derivative of the speed-time function.\n",
    "  * The inverse procedure, finding a function for which our original function is the derivative, is called the **anti-derivative**. For our speed-time example, the anti-derivative would be the **distance-time functio**n, as the rate of change of distance is speed. The anti-derivative is closely related to an integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c03f1",
   "metadata": {},
   "source": [
    "## A2. Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d01ce8",
   "metadata": {},
   "source": [
    "* Defining the Derivative\n",
    "  * The derivative is the formal mathematical notation for the gradient of a function. For a linear function with a constant gradient, the slope is defined as \"**rise over run**.\"\n",
    "  * For a non-linear function where the gradient changes at every point, we define the derivative at a specific point $x$ by taking the limit of the \"rise over run\" formula. We consider a second point that is an infinitesimally small distance $Δx$ away from the first point. As this distance approaches zero, the line connecting the two points becomes a perfect approximation of the tangent line at point $x$. $$ \\frac{df}{dx} = f'(x) = \\lim_{Δx\\to0} (\\frac{f(x+Δx)-f(x)}{Δx}) $$\n",
    "    * The notation for the derivative can be either $f'(x)$ (read as \"f prime of x\")\n",
    "    * or $\\frac{df}{dx}$ (read as \"df by dx\"). \n",
    "    * The key idea is that we are not dividing by zero, but rather observing the behavior of the expression as $Δx$ gets extremely close to zero.\n",
    "* Fundamental Rules of Differentiation\n",
    "  * This definition, while powerful, can be tedious to apply directly to every function. Fortunately, we can derive and use general rules to simplify the process.\n",
    "  * **The Sum Rule**\n",
    "    * The derivative of a sum of functions is the sum of their individual derivatives. This means you can differentiate each term in a function separately and then add the results together.\n",
    "    * Example: The derivative of $f(x)=3x+2$ is the derivative of $3x$ plus the derivative of $2$.\n",
    "  * ** The Power Rule**\n",
    "    * For a function in the form of $f(x) = ax^b$, its derivative is:\n",
    "    $$ f(x) = ax^b $$\n",
    "    $$ f'(x) = abx^{(b-1)} $$\n",
    "    * The rule is: multiply the coefficient by the original power, and then subtract 1 from the power.\n",
    "    * Example: For $f(x) = 5x^2$, the derivative is $f'(x)=(5)(2)x^{2-1}=10x^1=10x$\n",
    "* Special cases\n",
    "  * The Derivative of $\\frac{1}{x}$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
