# Mathematics for Machine Learning â€“ Notes & Python Visualizations ğŸ“

This repository contains my personal learning notes, Python implementations, and visual explanations based on the **Mathematics for Machine Learning Specialization** by Imperial College London.

> The goal of this project is to build strong mathematical intuition for machine learning, reinforced through code and visual storytelling.

---

## ğŸ” Specialization Overview

This 3-course series bridges the gap between academic math and its applications in Data Science & Machine Learning. Each course combines theory with hands-on Jupyter notebooks and interactive visualizations.

| Course | Title                              | Description                                                                                |
| ------ | ---------------------------------- | ------------------------------------------------------------------------------------------ |
| ğŸ“˜ 1    | [Linear Algebra](https://github.com/JohnsonIsHere/mathematics-for-machine-learning-notes/tree/main/linear-algebra)                     | Understand vectors, matrices, basis transformations, and how they relate to ML             |
| ğŸ“— 2    | Multivariate Calculus              | Learn optimization, gradients, chain rule, and backpropagation                             |
| ğŸ“™ 3    | Principal Component Analysis (PCA) | Use linear algebra & calculus to perform dimensionality reduction on high-dimensional data |

ğŸ§‘â€ğŸ« **Instructors:**  
David Dye ãƒ» Samuel J. Cooper ãƒ» Marc Peter Deisenroth ãƒ» A. Freddie Page  
*Imperial College London*

---

## ğŸ“š Chapters & Learning Notes

### ğŸ“˜ Mathematics for Machine Learning: Linear Algebra

- A. Introduction to Linear Algebra  
  - A1. What is a vector?  
  - A2. Vector addition  
  - A3. Vector multiplication  

- B. Vectors and Dot Products  
  - B1. Length of vectors  
  - B2. Dot product  
  - B3. Cosine rule  
  - B4. Vector projection  
  - B5. Changing basis  
  - B6. Vector space and linear independence  

- C. Matrices  
  - C1. What is a matrix?  
  - C2. Matrix operations  
  - C3. Composition of transformations  
  - C4. Matrix inverses  
  - C5. Determinants & special matrices  

> ğŸ§  Upcoming:
> - D. Matrices make linear mappings
> - E. Eigenvalues and Eigenvectors

---

### ğŸ“— Mathematics for Machine Learning: Multivariate Calculus

- A. Introduction to Functions  
- B. Limits and Continuity  
- C. Partial Derivatives  
- D. Gradient Vectors  
- E. Chain Rule in Multiple Dimensions  
- F. Jacobian and Hessian  
- G. Optimization & Critical Points  
- H. Backpropagation & Application in Neural Networks  

> ğŸ› ï¸ Coming soon

---

### ğŸ“™ Mathematics for Machine Learning: PCA (Dimensionality Reduction)

- A. What is PCA and why it matters  
- B. Covariance matrices & eigen decomposition  
- C. Eigenvalues and eigenvectors  
- D. Explained variance  
- E. Dimensionality reduction in practice  
- F. PCA on real-world data (e.g., MNIST)  
- G. Python implementation using NumPy and Scikit-learn  

> ğŸ› ï¸ Coming soon
---

## ğŸ’» Tools Used

- Python 3.x
- Jupyter Notebook
- NumPy, Matplotlib
- SymPy (for symbolic math)
- Scikit-learn (for PCA)

---

## ğŸ§  Author

**JT Y.** â€“ Data Scientist & M.Sc. student in Project Management & Data Science @ HTW Berlin  
[LinkedIn](https://www.linkedin.com/in/jt-y-37a299174/) ãƒ» [Medium](https://medium.com/@johnsonxxx0926) ãƒ» [GitHub](https://github.com/JohnsonIsHere)

> "Mathematics is the bridge between the abstract and the applicable â€” and machine learning walks right on it."

---

## â­ Related Projects

- [Essential Math for Data Science ğŸ“˜](https://github.com/JohnsonIsHere/essential-math-ds-notes)

---

## ğŸ“œ License

MIT License Â© 2025 JT Y.
